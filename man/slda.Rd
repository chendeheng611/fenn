% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/slda.R
\name{slda}
\alias{slda}
\title{Scaled Linear Discriminant Analysis}
\usage{
slda(x, \dots)

\method{slda}{formula}(formula, data, \dots, subset, na.action)

\method{slda}{default}(x, grouping, prior = proportions, tol = 1.0e-4, \dots)
                      
\method{slda}{data.frame}(x, \dots)

\method{slda}{matrix}(x, grouping, \dots, subset, na.action)
}
\arguments{
\item{x}{(required if no formula is given as the principal argument.)
a matrix or data frame or Matrix containing the explanatory variables.}

\item{\dots}{arguments passed to or from other methods.}

\item{formula}{A formula of the form \code{groups ~ x1 + x2 + \dots}  That is, the
response is the grouping factor and the right hand side specifies
the (non-factor) discriminators.}

\item{data}{Data frame from which variables specified in \code{formula} are
preferentially to be taken.}

\item{grouping}{(required if no formula principal argument is given.)
a factor specifying the class for each observation.}

\item{prior}{the prior probabilities of class membership.  If unspecified, the
class proportions for the training set are used.  If present, the
probabilities should be specified in the order of the factor levels.}

\item{tol}{A tolerance to decide if a matrix is singular; it will be used to modify
the scatter matrices by stabilizing eigne values less that \code{tol^2}.}

\item{subset}{An index vector specifying the cases to be used in the training
sample.  (NOTE: If given, this argument must be named.)}

\item{na.action}{A function to specify the action to be taken if \code{NA}s are found.
The default action is for the procedure to fail.  An alternative is
\code{na.omit}, which leads to rejection of cases with missing values on
any required variable.  (NOTE: If given, this argument must be named.)}
}
\value{
An object of class \code{"slda"} containing the following components:
\item{prior}{The prior probabilities used.}
\item{counts}{The group counts.}
\item{means}{The group means.}
\item{X.S}{The matrix of projections into similarity directions. Same as average within class
           covariance matrices.}
\item{X.D}{The matrix of projections into dissimilarity directions. Same as \code{X.S + (n/n-1) * Cov(m)},
           where \code{m} is the class means.}
\item{X_D_neg_1_2}{The matrix \code{X.D} raised to the power -1/2. This is the scaling that is applied
                   to data points before hand to generate the tilde transformed data points.}
\item{S_1_2}{The learned optimal transformation that should be applied to tilde transformed data points.}
\item{X_tilde_S}{The hamiltonian generated from data points.}
\item{informative.dims}{The index of informative directions in the optimal space. Can be used for dimension reduction.}
\item{muVec}{The automatically selected path of \code{mu} (temperature) values.}
\item{best.mu}{The the optimal (temperature) parameter obtained by maximizing Fisher Information.}
\item{E}{The average Energy for an automatically selected path of \code{mu} values \code{muVec}.}
\item{dE}{The Fisher Information of \code{mu}.}
\item{scaling}{The weights (eigen values) of maximum dissimilarity directions (eigenvectors of \code{S_1_2}).}
\item{x.tilde}{The tilde transformed data.}
\item{x.slda}{The \code{slda} transformed data.}
\item{N}{The number of observations used.}
\item{groupings}{The class variable of original data points.}
\item{call}{The (matched) function call.}
}
\description{
Fits a Scaled Linear Discriminant model (SLDA) via a Von Neumann entropy penalized
             distance metric learning formulation.
}
\details{
The function fits an Von Neumann Entropy penalized distance metric learning problem
to identify informative features and directions of maximam dissimilarity in the multi class case.
The method automatically finds the optimal value of the entropy tuning parameter by maximizing the
Fisher Information. The method can be used for sinlge class case to identify informative directions 
as well as multi class case to identiy directions of maximum dissimilarity. In the multi class case,
optimal solution is an optimally scaled lda for maximum  separability between classes that can results
in more accurate classification.

Specifying the \code{prior} will affect the classification unless over-ridden in \code{predict.slda}.
}
\note{
This function may be called giving either a formula and optional data frame, or a matrix and
grouping factor as the first two arguments.  All other arguments are optional, but \code{subset=} and
\code{na.action=}, if required, must be fully named.

If a formula is given as the principal argument the object may be modified using \code{update()} in 
the usual way.
}
\examples{
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
train <- sample(1:150, 75)
table(Iris$Sp[train])
## your answer may differ
##  c  s  v
## 22 23 30
z <- slda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train)
predict(z, Iris[-train, ])$class
##  [1] s s s s s s s s s s s s s s s s s s s s s s s s s s s c c c
## [31] c c c c c c c v c c c c v c c c c c c c c c c c c v v v v v
## [61] v v v v v v v v v v v v v v v
(z1 <- update(z, . ~ . - Petal.W.))

}
\seealso{
\code{\link{predict.slda}}
}
